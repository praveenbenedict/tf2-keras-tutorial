{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20f7a934-fc4b-4892-b982-07c69f76f376",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-datasets\n",
      "  Downloading tensorflow_datasets-4.8.2-py3-none-any.whl (5.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting etils[enp,epath]>=0.9.0\n",
      "  Downloading etils-1.0.0-py3-none-any.whl (146 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.5/146.5 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets) (1.23.1)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets) (1.14.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets) (4.64.0)\n",
      "Collecting dm-tree\n",
      "  Downloading dm_tree-0.1.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (153 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets) (8.1.3)\n",
      "Collecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets) (3.19.4)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets) (1.1.0)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets) (1.1.0)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-1.12.0-py3-none-any.whl (52 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets) (2.28.1)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets) (0.3.5.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from tensorflow-datasets) (5.9.1)\n",
      "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.9/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets) (5.8.0)\n",
      "Requirement already satisfied: zipp in /usr/local/lib/python3.9/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets) (3.8.1)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.9/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets) (4.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->tensorflow-datasets) (1.26.10)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from promise->tensorflow-datasets) (1.14.0)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.58.0-py2.py3-none-any.whl (223 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.0/223.0 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf>=3.12.2\n",
      "  Downloading protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21486 sha256=dcee4daffb9183e0fb891a769af03a8a353229fe45c6872eb93573072fb7abfd\n",
      "  Stored in directory: /root/.cache/pip/wheels/e1/e8/83/ddea66100678d139b14bc87692ece57c6a2a937956d2532608\n",
      "Successfully built promise\n",
      "Installing collected packages: dm-tree, toml, protobuf, promise, etils, googleapis-common-protos, tensorflow-metadata, tensorflow-datasets\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.4\n",
      "    Uninstalling protobuf-3.19.4:\n",
      "      Successfully uninstalled protobuf-3.19.4\n",
      "  Attempting uninstall: etils\n",
      "    Found existing installation: etils 0.6.0\n",
      "    Uninstalling etils-0.6.0:\n",
      "      Successfully uninstalled etils-0.6.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed dm-tree-0.1.8 etils-1.0.0 googleapis-common-protos-1.58.0 promise-2.3 protobuf-3.20.3 tensorflow-datasets-4.8.2 tensorflow-metadata-1.12.0 toml-0.10.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d6fe01a-c895-446c-a1eb-9e8d34630bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# To Avoid GPU errors\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e378c9f-90a4-4249-9aef-0806c2a348ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bbf8d0294d642f58016dedc67f13400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist', \n",
    "    split = ['train', 'test'],\n",
    "    shuffle_files = True, \n",
    "    as_supervised = True, \n",
    "    with_info = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9501d9a3-ca92-467d-a37a-0e1c2b6c836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "    #normalize images\n",
    "    return tf.cast(image, tf.float32)/255.0, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54b8ef17-b9f4-4fda-af9a-5ba0682ba5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "ds_train = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3a3ed1d-aada-434a-8fb5-b955c689374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits[\"train\"].num_examples)\n",
    "ds_train = ds_train.batch(BATCH_SIZE)\n",
    "ds_train = ds_train.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e223d965-d983-48b0-b32d-c4c5b6b5dcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = ds_test.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_train = ds_train.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b661ddf3-1da0-481a-8c4e-3ef346204fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c8b46b3-b7ff-40d6-910e-e7cc75e6fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input((28, 28, 1)),\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "131f3aac-a0e1-4251-a812-251f045ba6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_callback = keras.callbacks.ModelCheckpoint(\n",
    "    'checkpoint/',\n",
    "    save_weights_only=True, \n",
    "    monitor='accuracy',\n",
    "    save_best_only=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbd80e71-4000-441d-a8cf-88ff37bbd558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 2:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e991207-655e-4d7b-a727-9d983ffeadde",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(scheduler, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2625b30c-f26f-4130-82ad-8fc02a1324a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.Adam(lr=0.001),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "175a656f-df23-4218-8535-65098c7281d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/5\n",
      "938/938 - 11s - loss: 0.2108 - accuracy: 0.9397 - lr: 0.0010 - 11s/epoch - 12ms/step\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 2/5\n",
      "938/938 - 5s - loss: 0.0732 - accuracy: 0.9786 - lr: 0.0010 - 5s/epoch - 5ms/step\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0009900000470224768.\n",
      "Epoch 3/5\n",
      "938/938 - 4s - loss: 0.0519 - accuracy: 0.9845 - lr: 9.9000e-04 - 4s/epoch - 4ms/step\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.000980100086890161.\n",
      "Epoch 4/5\n",
      "938/938 - 10s - loss: 0.0412 - accuracy: 0.9875 - lr: 9.8010e-04 - 10s/epoch - 11ms/step\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0009702991275116801.\n",
      "Epoch 5/5\n",
      "938/938 - 4s - loss: 0.0315 - accuracy: 0.9905 - lr: 9.7030e-04 - 4s/epoch - 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4bd45df1c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds_train, epochs=5, verbose=2, callbacks=[save_callback, lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e51f56-6c47-466b-8f69-fcfa9948790f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8195aa-aff5-4ec9-895a-936524a0b94a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac637fe5-9241-47ca-a134-3c86d678a158",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(logs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bcac5c8-ac18-4f4c-884c-9c652883e6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.Adam(lr=0.001),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20991d49-c442-434a-8489-bb4df075c520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/5\n",
      "dict_keys(['loss', 'accuracy', 'lr'])\n",
      "938/938 - 7s - loss: 0.0274 - accuracy: 0.9916 - lr: 0.0010 - 7s/epoch - 7ms/step\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 2/5\n",
      "dict_keys(['loss', 'accuracy', 'lr'])\n",
      "938/938 - 4s - loss: 0.0216 - accuracy: 0.9933 - lr: 0.0010 - 4s/epoch - 4ms/step\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0009900000470224768.\n",
      "Epoch 3/5\n",
      "dict_keys(['loss', 'accuracy', 'lr'])\n",
      "938/938 - 12s - loss: 0.0157 - accuracy: 0.9956 - lr: 9.9000e-04 - 12s/epoch - 13ms/step\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.000980100086890161.\n",
      "Epoch 4/5\n",
      "dict_keys(['loss', 'accuracy', 'lr'])\n",
      "938/938 - 4s - loss: 0.0121 - accuracy: 0.9968 - lr: 9.8010e-04 - 4s/epoch - 4ms/step\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0009702991275116801.\n",
      "Epoch 5/5\n",
      "dict_keys(['loss', 'accuracy', 'lr'])\n",
      "938/938 - 4s - loss: 0.0097 - accuracy: 0.9975 - lr: 9.7030e-04 - 4s/epoch - 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4b62e67f70>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds_train, epochs=5, verbose=2, callbacks=[save_callback, lr_scheduler, CustomCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62325fd9-f7ef-4800-9925-80cebe4a1ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba2e4ff-1aec-4ade-b701-c28a00f52970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7acc2463-87de-4d29-a966-f78375df0602",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs.get('accuracy') > 0.90:\n",
    "            print('Accuracy over 90%, quitting training')\n",
    "            self.model.stop_training = True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d9fe27d-50b7-44e3-92a6-73be0d0dadbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.Adam(lr=0.001),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa413af3-899f-409e-a128-914ed0d27e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/5\n",
      "Accuracy over 90%, quitting training\n",
      "938/938 - 4s - loss: 0.0096 - accuracy: 0.9973 - lr: 0.0010 - 4s/epoch - 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4b63478040>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds_train, epochs=5, verbose=2, callbacks=[save_callback, lr_scheduler, CustomCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed3b9fc-f480-4f20-a92e-b52624cc175f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
